{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import os\n",
    "\n",
    "import time\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from model.dataloader import HELMETDataLoader\n",
    "from model.dataloader import class_dict\n",
    "from model.models import Darknet, load_weights, load_darknet_weights\n",
    "from utils.utils import *\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = './cfg/yolov3_36.cfg'\n",
    "weights_path = './weights/darknet53.conv.74'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "\n",
    "# Load in convolutional darknet.\n",
    "# TODO: Set a default img_size for convenience.\n",
    "def get_darknet(img_size, cfg=cfg_path):\n",
    "    return Darknet(cfg, img_size)\n",
    "\n",
    "img_size = 416\n",
    "\n",
    "model = get_darknet(img_size=img_size)\n",
    "\n",
    "# Load in weights\n",
    "load_darknet_weights(model, weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "\n",
    "dataloader = HELMETDataLoader(\"./data/HELMET_DATASET_DUMMY\", shuffle=True, batch_size=batch_size, resize=(img_size, img_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader unit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([3, 416, 416])\n",
      "Output shape: torch.Size([1, 10647, 41])\n",
      "Targets shape: torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(dataloader))\n",
    "\n",
    "imgs, targets, annotations = batch\n",
    "\n",
    "print('Image shape:', imgs[0].shape)\n",
    "\n",
    "out = model(imgs[0].reshape(1, 3, img_size, img_size))\n",
    "\n",
    "print('Output shape:', out.shape)\n",
    "print('Targets shape:', targets[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43095"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 * 3 * (85) * 13 * 13 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 416, 416])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[0].reshape(1, 3, img_size, img_size).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection \"unit test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda = torch.cuda.is_available()\n",
    "device = 'cpu' # device = torch.device('cuda:0' if cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {'conf_thres': .5, \n",
    "       'nms_thres': .45\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system('rm -rf ' + opt.output_folder)\n",
    "# os.makedirs(opt.output_folder, exist_ok=True)\n",
    "\n",
    "model.to(device).eval()\n",
    "\n",
    "# Set Dataloader\n",
    "# classes = load_classes(opt.class_path)  # Extracts class labels from file\n",
    "# dataloader = load_images(opt.image_folder, batch_size=opt.batch_size, img_size=opt.img_size)\n",
    "\n",
    "imgs = []  # Stores image paths\n",
    "img_detections = []  # Stores detections for each image index\n",
    "# for batch_i, (img_paths, img) in enumerate(dataloader):\n",
    "#     print(batch_i, img.shape, end=' ')\n",
    "\n",
    "batch = next(iter(dataloader))\n",
    "\n",
    "batch_imgs, batch_targets, batch_annotations = batch\n",
    "\n",
    "# Get detections\n",
    "with torch.no_grad():\n",
    "    # chip = torch.from_numpy(img).unsqueeze(0).to(device)\n",
    "    pred = model(batch_imgs[0].reshape(1, 3, 832, 832)) # pred = model(chip)\n",
    "    pred = pred[pred[:, :, 4] > opt['conf_thres']]\n",
    "\n",
    "    if len(pred) > 0:\n",
    "        detections = non_max_suppression(pred.unsqueeze(0), opt['conf_thres'], opt['nms_thres'])\n",
    "        img_detections.extend(detections)\n",
    "        # imgs.extend(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.array(batch_imgs[0]).transpose([1, 2, 0]))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bugfix :D\n",
    "# model.to(device).train()\n",
    "# train_batch = torch.rand((3, 3, 832, 832))\n",
    "# targets = [ torch.tensor([[1, .5, .5, .2, .2], [1, .4, .4, .2, .2]]) ,  torch.tensor([[1, .5, .5, .2, .2]]) , torch.tensor([]) ]\n",
    "# model(train_batch, targets, requestPrecision=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUTOFF = 155\n",
    "# Transfer learning (train only YOLO layers)\n",
    "for i, (name, p) in enumerate(model.named_parameters()):\n",
    "    # print(i, p.shape[0], name)\n",
    "    # if p.shape[0] != 650:  # not YOLO layer\n",
    "    #    p.requires_grad = False\n",
    "    if i > CUTOFF:\n",
    "        p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "optimizer = torch.optim.SGD(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3,\n",
    "    momentum=.9, weight_decay=5e-4, nesterov=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_enable = False\n",
    "cuda_available = torch.cuda.is_available()\n",
    "if cuda_enable and cuda_available:\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ITERATIONS = 10\n",
    "PLOT_EVERY = 1\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "plot_dict = {'train_loss': [], 'train_acc': [], 'Epoch': []}\n",
    "\n",
    "# imgs, targets, annotations = next(iter(dataloader))\n",
    "# targets = list(map(lambda x: x.type(torch.FloatTensor), targets)) # To correct type.\n",
    "\n",
    "for epoch in range(1, N_ITERATIONS + 1):\n",
    "    since = time.time()\n",
    "    \n",
    "    imgs, targets, annotations = next(iter(dataloader))\n",
    "    targets = list(map(lambda x: x.type(torch.FloatTensor), targets)) # To correct type.\n",
    "    \n",
    "    # Train\n",
    "    model.train()\n",
    "    optimizer.zero_grad() # Zero gradients\n",
    "    loss = model(imgs.to(device), targets, requestPrecision=False)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    time_elapsed = time.time() - since  \n",
    "    print('Train Time {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    if not (epoch - 1) % PLOT_EVERY:\n",
    "        plot_dict['Epoch'].append(epoch)\n",
    "        plot_dict['train_loss'].append(loss.detach().numpy())\n",
    "        # plot_dict['train_acc'].append(1-trn_err)\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(7.5, 5))\n",
    "        ax.plot(plot_dict['Epoch'], plot_dict['train_loss'])\n",
    "        ax.set_xlabel('Epochs')\n",
    "        ax.set_ylabel('Loss')\n",
    "        # axs[1].plot(plot_dict['Epoch'], plot_dict['train_acc'])\n",
    "        # axs[1].set_xlabel('Epochs')\n",
    "        # axs[1].set_ylabel('Accuracy')\n",
    "        plt.show()\n",
    "    clear_output(wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device).eval()\n",
    "img_detections = []\n",
    "\n",
    "# Get detections\n",
    "with torch.no_grad():\n",
    "    pred = model(imgs[0].reshape(1, 3, 832, 832)) # pred = model(chip)\n",
    "    pred = pred[pred[:, :, 4] > opt['conf_thres']]\n",
    "\n",
    "    if len(pred) > 0:\n",
    "        detections = non_max_suppression(pred.unsqueeze(0), opt['conf_thres'], opt['nms_thres'])\n",
    "        img_detections.extend(detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imgs[0]\n",
    "detections = img_detections[0]\n",
    "\n",
    "# The amount of padding that was added\n",
    "pad_x = max(img.shape[0] - img.shape[1], 0) * (img_size / max(img.shape))\n",
    "pad_y = max(img.shape[1] - img.shape[0], 0) * (img_size / max(img.shape))\n",
    "# Image height and width after padding is removed\n",
    "unpad_h = img_size - pad_y\n",
    "unpad_w = img_size - pad_x\n",
    "\n",
    "# Draw bounding boxes and labels of detections\n",
    "if detections is not None:\n",
    "    unique_classes = detections[:, -1].cpu().unique()\n",
    "\n",
    "    for i in unique_classes:\n",
    "        n = (detections[:, -1].cpu() == i).sum()\n",
    "        # print('%g %ss' % (n, classes[int(i)]))\n",
    "\n",
    "    for x1, y1, x2, y2, conf, cls_conf, cls_pred in detections:\n",
    "        # Rescale coordinates to original dimensions\n",
    "        box_h = ((y2 - y1) / unpad_h) * img.shape[0]\n",
    "        box_w = ((x2 - x1) / unpad_w) * img.shape[1]\n",
    "        y1 = (((y1 - pad_y // 2) / unpad_h) * img.shape[0]).round().item()\n",
    "        x1 = (((x1 - pad_x // 2) / unpad_w) * img.shape[1]).round().item()\n",
    "        x2 = (x1 + box_w).round().item()\n",
    "        y2 = (y1 + box_h).round().item()\n",
    "        x1, y1, x2, y2 = max(x1, 0), max(y1, 0), max(x2, 0), max(y2, 0)\n",
    "        # print(x1, y1, x2, y2)\n",
    "        # print(int(cls_pred))\n",
    "        print(list(class_dict.keys())[int(cls_pred)])\n",
    "# print(annotations[0])\n",
    "# detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.array(img).transpose([1, 2, 0]))\n",
    "plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c979434bdbac1e78441464ad15ad8d73f5f7845a1d8d619400dbe30b7f4c19d4"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
